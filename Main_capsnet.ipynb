{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611b5ec1-af85-468a-f91d-8e277af1f0cb"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "!pip install patool\n",
        "import patoolib\n",
        "import scipy.io\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "drive.mount('/content/gdrive')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_",
        "outputId": "83912f1a-a737-4017-9ca5-1865fc9725dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sim_dir =  '/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
        "\n",
        "for rar in glob.glob(sim_dir + '*.rar'):\n",
        "  patoolib.extract_archive(rar, outdir=sim_dir)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_ellipses.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_ellipses.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_ellipses.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_both.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_both.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_both.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_spheres.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_spheres.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/two_spheres.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_both.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_both.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_both.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_ellipses.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_ellipses.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_ellipses.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_spheres.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_spheres.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/three_spheres.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_ellipses.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_ellipses.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_ellipses.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/homogenous.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/homogenous.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/homogenous.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_spheres.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_spheres.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_spheres.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/one_ellipse.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/one_ellipse.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/one_ellipse.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n",
            "patool: Extracting /content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_both.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_both.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'\n",
            "patool: ... /content/gdrive/My Drive/פרויקט מסכם/new_simulations/four_both.rar extracted to `/content/gdrive/My Drive/פרויקט מסכם/new_simulations/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "labels = []\n",
        "i = 0\n",
        "for file in glob.glob(sim_dir + '*/*.mat'):\n",
        "  i += 1\n",
        "  if i%100==0:\n",
        "    print(i)\n",
        "  mat = scipy.io.loadmat(file)['logY'].toarray()\n",
        "  dataset.append(mat)\n",
        "  if \"homogenous\" in file:\n",
        "    labels.append(0)\n",
        "  else: \n",
        "    labels.append(1)\n",
        "dataset = np.real(np.array(dataset))\n",
        "labels = np.array(labels)\n",
        "np.save(sim_dir + \"dataset.npy\", dataset)\n",
        "np.save(sim_dir + \"labels.npy\", labels)\n",
        "\n",
        "# dataset = np.load('/content/gdrive/My Drive/פרויקט מסכם/new_simulations/dataset.npy')\n",
        "# labels = np.load('/content/gdrive/My Drive/פרויקט מסכם/new_simulations/labels.npy')"
      ],
      "metadata": {
        "id": "2_7WPrhjs5Aw",
        "outputId": "ae722fe1-2805-47ea-fc4b-e2639932f091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "# for i in range(1,5):\n",
        "#   print(x_train_norm[i])\n",
        "#   print(t_train[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9dBLWaxIpp",
        "outputId": "0acf8fbe-0cd7-4247-b406-af4e5cf18dee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5950, 25, 25)\n",
            "(5950,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def norm_data(data):\n",
        "  output = []\n",
        "  for sample in data: \n",
        "    sample = (sample - np.mean(sample))/np.std(sample)\n",
        "    output.append(np.array(sample))\n",
        "  return np.array(output)\n",
        "\n",
        "input_size = 25*25\n",
        "num_of_samples = dataset.shape[0]\n",
        "\n",
        "perm = torch.randperm(num_of_samples)\n",
        "dataset = dataset[perm]\n",
        "labels = labels[perm]\n",
        "\n",
        "x_train, x_val, x_test = dataset[:round(0.7*num_of_samples)], dataset[round(0.7*num_of_samples):round(0.9*num_of_samples)], dataset[round(0.9*num_of_samples):]\n",
        "t_train, t_val, t_test = labels[:round(0.7*num_of_samples)],  labels[round(0.7*num_of_samples):round(0.9*num_of_samples)],  labels[round(0.9*num_of_samples):]\n",
        "\n",
        "x_train_norm = norm_data(x_train)\n",
        "x_val_norm = norm_data(x_val)\n",
        "x_test_norm = norm_data(x_test)\n",
        "\n",
        "x_train_norm = np.reshape(x_train_norm, (x_train_norm.shape[0], x_train_norm.shape[1]*x_train_norm.shape[2]))\n",
        "x_val_norm = np.reshape(x_val_norm, (x_val_norm.shape[0], x_val_norm.shape[1]*x_val_norm.shape[2]))\n",
        "x_test_norm = np.reshape(x_test_norm, (x_test_norm.shape[0], x_test_norm.shape[1]*x_test_norm.shape[2]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_train[:,None], x_train_norm),axis=1),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_val[:,None], x_val_norm),axis=1),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_test[:,None], x_test_norm),axis=1),\n",
        "    batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "unFA2G0nNX-i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size=9, num_hidden=50):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, num_hidden)\n",
        "        self.layer2 = nn.Linear(num_hidden, num_hidden//2)\n",
        "        self.layer3 = nn.Linear(num_hidden//2, 2)\n",
        "        self.num_hidden = num_hidden\n",
        "        self.input_size = input_size\n",
        "    def forward(self, x):\n",
        "        x = x.reshape([-1, input_size])\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x \n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, n_feature):\n",
        "        super(CNN, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5, padding='same')\n",
        "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5, padding='same')\n",
        "        self.fc1 = nn.Linear(n_feature*6*6, 50)\n",
        "        self.fc2 = nn.Linear(50, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = x.view(-1, self.n_feature*6*6)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BY07RPjnMdDU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, loader=train_loader):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    pred_list = []\n",
        "    true_list = []\n",
        "    for ar in loader:\n",
        "        data = ar[:,1:]\n",
        "        label = ar[:,0]\n",
        "        # send to device\n",
        "        data, label = data.to(device), label.to(device)\n",
        "\n",
        "        data = data.view(-1, 25*25)\n",
        "        data = data.view(-1, 1, 25, 25)\n",
        "        \n",
        "        pred = model(data)\n",
        "        loss += F.nll_loss(pred, label.long(), reduction='sum').item() # sum up batch loss                                                               \n",
        "        pred = pred.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(label.data.view_as(pred)).cpu().sum().item()\n",
        "    # print(f\"correct = {correct}\")\n",
        "    # print(f\"num_of_ars = {num_of_ars}\")\n",
        "    loss /= len(loader.dataset)\n",
        "    accuracy = 100. * correct / len(loader.dataset)\n",
        "    \n",
        "    return loss, accuracy\n",
        "\n",
        "def train(model, lr=0.01, max_iters=1000,num_epochs=6):\n",
        "    model.train()\n",
        "    train_accs, valid_accs = [], []\n",
        "    epochs = []\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    n = 0 # the number of iterations\n",
        "    iters, losses = [], []\n",
        "    iters_sub = []\n",
        "\n",
        "    for epoch in range(0, num_epochs):\n",
        "\n",
        "        for batch_idx, ar in enumerate(train_loader):           \n",
        "            data = ar[:,1:]\n",
        "            label = ar[:,0]\n",
        "            # send to device\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            data = data.view(-1, 25*25)\n",
        "            data = data.view(-1, 1, 25, 25)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(data)\n",
        "            loss = F.nll_loss(pred, label.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            iters.append(n)\n",
        "            losses.append(loss)\n",
        "\n",
        "            if batch_idx % 64 == 0: \n",
        "                \n",
        "                iters_sub.append(n)\n",
        "                train_loss, train_acc = get_accuracy(model, loader=train_loader)\n",
        "                train_accs.append(train_acc)\n",
        "\n",
        "                valid_loss, valid_acc = get_accuracy(model, loader=val_loader)\n",
        "                valid_accs.append(valid_acc)\n",
        "      \n",
        "                print(\"Iter %d. [Val Acc %.0f%%] [Train Acc %.0f%%, Loss %f]\" % (n, valid_acc, train_acc, train_loss))\n",
        "\n",
        "            # increment the iteration number\n",
        "            n += 1\n",
        "            if n > max_iters:\n",
        "                return iters, losses, iters_sub, train_accs, valid_accs\n",
        "    return iters, losses, iters_sub, train_accs, valid_accs"
      ],
      "metadata": {
        "id": "37QPep2hPf-P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = CNN(input_size, 10)\n",
        "model.to(device)\n",
        "\n",
        "lr = 0.0001\n",
        "\n",
        "iters, losses, iters_sub, train_accs, valid_accs = train(model.double(), lr=lr, max_iters=10000, num_epochs=15)"
      ],
      "metadata": {
        "id": "D3meXB8WZo9T",
        "outputId": "4f3a6aca-1e8b-49a1-a282-73a15b4f772a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0. [Val Acc 12%] [Train Acc 11%, Loss 0.713430]\n",
            "Iter 44. [Val Acc 88%] [Train Acc 89%, Loss 0.398231]\n",
            "Iter 88. [Val Acc 88%] [Train Acc 89%, Loss 0.350297]\n",
            "Iter 132. [Val Acc 88%] [Train Acc 89%, Loss 0.350346]\n",
            "Iter 176. [Val Acc 88%] [Train Acc 89%, Loss 0.350065]\n",
            "Iter 220. [Val Acc 88%] [Train Acc 89%, Loss 0.350441]\n",
            "Iter 264. [Val Acc 88%] [Train Acc 89%, Loss 0.350843]\n",
            "Iter 308. [Val Acc 88%] [Train Acc 89%, Loss 0.351156]\n",
            "Iter 352. [Val Acc 88%] [Train Acc 89%, Loss 0.350174]\n",
            "Iter 396. [Val Acc 88%] [Train Acc 89%, Loss 0.350161]\n",
            "Iter 440. [Val Acc 88%] [Train Acc 89%, Loss 0.350296]\n",
            "Iter 484. [Val Acc 88%] [Train Acc 89%, Loss 0.350213]\n",
            "Iter 528. [Val Acc 88%] [Train Acc 89%, Loss 0.349887]\n",
            "Iter 572. [Val Acc 88%] [Train Acc 89%, Loss 0.350938]\n",
            "Iter 616. [Val Acc 88%] [Train Acc 89%, Loss 0.349866]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "# from torchvision import datasets, transforms\n",
        "# from capsnet import CapsNet\n",
        "# from data_loader import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "USE_CUDA = True if torch.cuda.is_available() else False\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 100\n",
        "LEARNING_RATE = 0.01\n",
        "MOMENTUM = 0.9\n",
        "n_features = 10\n",
        "'''\n",
        "Config class to determine the parameters for capsule net\n",
        "'''\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        # CNN (cnn)\n",
        "        self.cnn_in_channels = 1\n",
        "        self.cnn_out_channels = 256\n",
        "        self.cnn_kernel_size = 9\n",
        "\n",
        "        # Primary Capsule (pc)\n",
        "        self.pc_num_capsules = 8\n",
        "        self.pc_in_channels = 256\n",
        "        self.pc_out_channels = 32\n",
        "        self.pc_kernel_size = 9\n",
        "        self.pc_num_routes = 32 * 5 * 5\n",
        "\n",
        "        # Digit Capsule (dc)\n",
        "        self.dc_num_capsules = 2\n",
        "        self.dc_num_routes = 32 * 5 * 5\n",
        "        self.dc_in_channels = 8\n",
        "        self.dc_out_channels = 16\n",
        "\n",
        "        # Decoder\n",
        "        self.input_width = 25\n",
        "        self.input_height = 25\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "USE_CUDA = True if torch.cuda.is_available() else False\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
        "        super(ConvLayer, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=kernel_size,\n",
        "                              stride=1\n",
        "                              )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "\n",
        "class PrimaryCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9, num_routes=32 * 6 * 6):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "        self.num_routes = num_routes\n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n",
        "            for _ in range(num_capsules)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = [capsule(x) for capsule in self.capsules]\n",
        "        u = torch.stack(u, dim=1)\n",
        "        u = u.view(x.size(0), self.num_routes, -1)\n",
        "        return self.squash(u)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor\n",
        "\n",
        "\n",
        "class DigitCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=10, num_routes=32 * 6 * 6, in_channels=8, out_channels=16):\n",
        "        super(DigitCaps, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_routes = num_routes\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
        "\n",
        "        W = torch.cat([self.W] * batch_size, dim=0)\n",
        "        u_hat = torch.matmul(W, x)\n",
        "\n",
        "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
        "        if USE_CUDA:\n",
        "            b_ij = b_ij.cuda()\n",
        "\n",
        "        num_iterations = 3\n",
        "        for iteration in range(num_iterations):\n",
        "            c_ij = F.softmax(b_ij, dim=1)\n",
        "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
        "\n",
        "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
        "            v_j = self.squash(s_j)\n",
        "\n",
        "            if iteration < num_iterations - 1:\n",
        "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
        "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
        "\n",
        "        return v_j.squeeze(1)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_width=28, input_height=28, input_channel=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.input_width = input_width\n",
        "        self.input_height = input_height\n",
        "        self.input_channel = input_channel\n",
        "        self.reconstraction_layers = nn.Sequential(\n",
        "            nn.Linear(16 * 2, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, self.input_height * self.input_width * self.input_channel),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, data):\n",
        "        classes = torch.sqrt((x ** 2).sum(2))\n",
        "        classes = F.softmax(classes, dim=0)\n",
        "\n",
        "        _, max_length_indices = classes.max(dim=1)\n",
        "        masked = Variable(torch.sparse.torch.eye(2))\n",
        "        if USE_CUDA:\n",
        "            masked = masked.cuda()\n",
        "        masked = masked.index_select(dim=0, index=Variable(max_length_indices.squeeze(1).data))\n",
        "        t = (x * masked[:, :, None, None]).view(x.size(0), -1)\n",
        "        reconstructions = self.reconstraction_layers(t)\n",
        "        reconstructions = reconstructions.view(-1, self.input_channel, self.input_width, self.input_height)\n",
        "        return reconstructions, masked\n",
        "\n",
        "\n",
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, config=None):\n",
        "        super(CapsNet, self).__init__()\n",
        "        if config:\n",
        "            self.conv_layer = ConvLayer(config.cnn_in_channels, config.cnn_out_channels, config.cnn_kernel_size)\n",
        "            self.primary_capsules = PrimaryCaps(config.pc_num_capsules, config.pc_in_channels, config.pc_out_channels,\n",
        "                                                config.pc_kernel_size, config.pc_num_routes)\n",
        "            self.digit_capsules = DigitCaps(config.dc_num_capsules, config.dc_num_routes, config.dc_in_channels,\n",
        "                                            config.dc_out_channels)\n",
        "            self.decoder = Decoder(config.input_width, config.input_height, config.cnn_in_channels)\n",
        "        else:\n",
        "            self.conv_layer = ConvLayer()\n",
        "            self.primary_capsules = PrimaryCaps()\n",
        "            self.digit_capsules = DigitCaps()\n",
        "            self.decoder = Decoder()\n",
        "\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, data):\n",
        "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
        "        reconstructions, masked = self.decoder(output, data)\n",
        "        return output, reconstructions, masked\n",
        "\n",
        "    def loss(self, data, x, target, reconstructions):\n",
        "        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
        "\n",
        "    def margin_loss(self, x, labels, size_average=True):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        v_c = torch.sqrt((x ** 2).sum(dim=2, keepdim=True))\n",
        "\n",
        "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "\n",
        "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "        loss = loss.sum(dim=1).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def reconstruction_loss(self, data, reconstructions):\n",
        "        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
        "        return loss * 0.0005\n",
        "\n",
        "# def new_margin_loss(x, labels, size_average=True):\n",
        "#         batch_size = x.size(0)\n",
        "\n",
        "#         v_c = torch.sqrt((x ** 2).sum(dim=2, keepdim=True))\n",
        "\n",
        "#         left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "#         right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "#         loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "#         loss = loss.sum(dim=1).mean()\n",
        "\n",
        "#         return loss\n",
        "\n",
        "def train_capsnet(model, optimizer, train_loader, epoch):\n",
        "    capsule_net = model\n",
        "    capsule_net.train()\n",
        "    n_batch = len(list(enumerate(train_loader)))\n",
        "    total_loss = 0\n",
        "    for batch_id, ar in enumerate(train_loader):\n",
        "        data = ar[:,1:].type(torch.double)\n",
        "        target = ar[:,0].type(torch.int64)\n",
        "        target = torch.sparse.torch.eye(2).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        data = data.view(-1, 25*25)\n",
        "        data = data.view(-1, 1, 25, 25)\n",
        "\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct = sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
        "        train_loss = loss.item()\n",
        "        total_loss += train_loss\n",
        "        if batch_id % 100 == 0:\n",
        "            current_acc, current_loss = get_accuracy_capsnet(capsule_net, train_loader)\n",
        "            # tqdm.write(\n",
        "            #     \"Epoch: [{}/{}], train accuracy: {:.6f}%, loss: {:.6f}\".format(e, N_EPOCHS, valid_acc,\n",
        "            #                                                               valid_loss / len(val_loader)))\n",
        "            tqdm.write(\"Epoch: [{}/{}], Batch: [{}/{}], train accuracy: {:.6f}%, loss: {:.6f}\".format(\n",
        "                epoch,\n",
        "                N_EPOCHS,\n",
        "                batch_id + 1,\n",
        "                n_batch,\n",
        "                current_acc,\n",
        "                current_loss\n",
        "                ))\n",
        "    tqdm.write('Epoch: [{}/{}], train loss: {:.6f}'.format(epoch,N_EPOCHS,total_loss / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def get_accuracy_capsnet(capsule_net, loader):\n",
        "    capsule_net.eval()\n",
        "    final_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    pred_list = []\n",
        "    true_list = []\n",
        "    for batch_id, ar in enumerate(loader):\n",
        "        data = ar[:,1:].type(torch.double)\n",
        "        target = ar[:,0].type(torch.int64)\n",
        "        target = torch.sparse.torch.eye(2).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        data = data.view(-1, 25*25)\n",
        "        data = data.view(-1, 1, 25, 25)\n",
        "\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "\n",
        "        final_loss += loss.item()\n",
        "        correct += sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
        "                       np.argmax(target.data.cpu().numpy(), 1))\n",
        "        \n",
        "        for y in np.argmax(masked.data.cpu().numpy(), 1):\n",
        "          pred_list.append(y)\n",
        "\n",
        "        for y in np.argmax(target.data.cpu().numpy(), 1):  \n",
        "          true_list.append(y)\n",
        "\n",
        "    # conf_mat = confusion_matrix(true_list, pred_list, labels=list(range(0,9))+list(range(10,25)))  \n",
        "    acc = correct * 100 / len(loader.dataset)\n",
        "    \n",
        "    return acc, final_loss"
      ],
      "metadata": {
        "id": "iah_27sH8MgS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "config = Config()\n",
        "\n",
        "capsule_net = CapsNet(config)\n",
        "capsule_net = torch.nn.DataParallel(capsule_net)\n",
        "if USE_CUDA:\n",
        "    capsule_net = capsule_net.cuda()\n",
        "capsule_net = capsule_net.module.double()\n",
        "\n",
        "optimizer = torch.optim.Adam(capsule_net.parameters())\n",
        "# capsule_net.margin_loss = new_margin_loss\n",
        "for e in range(1, N_EPOCHS + 1):\n",
        "    train_capsnet(capsule_net, optimizer, train_loader, e)\n",
        "    valid_acc, valid_loss = get_accuracy_capsnet(capsule_net, val_loader)\n",
        "    tqdm.write(\n",
        "        \"Epoch: [{}/{}], validation accuracy: {:.6f}%, loss: {:.6f}\".format(e, N_EPOCHS, valid_acc,\n",
        "                                                                  valid_loss / len(val_loader)))\n",
        "\n",
        "torch.save(capsule_net.state_dict(),  \"/content/gdrive/My Drive/פרויקט מסכם/new_simulations/capsnet.pt\")"
      ],
      "metadata": {
        "id": "yc6ZNYeE8skC",
        "outputId": "7c9d183d-fdbc-4ef7-e9a5-2774f37ee429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/100], Batch: [1/66], train accuracy: 58.103241%, loss: 6.611827\n",
            "Epoch: [1/100], train loss: 0.001672\n",
            "Epoch: [1/100], validation accuracy: 51.008403%, loss: 0.088243\n",
            "Epoch: [2/100], Batch: [1/66], train accuracy: 51.308523%, loss: 6.247734\n",
            "Epoch: [2/100], train loss: 0.001468\n",
            "Epoch: [2/100], validation accuracy: 50.672269%, loss: 0.086947\n",
            "Epoch: [3/100], Batch: [1/66], train accuracy: 52.460984%, loss: 5.847939\n",
            "Epoch: [3/100], train loss: 0.001412\n",
            "Epoch: [3/100], validation accuracy: 52.184874%, loss: 0.088374\n",
            "Epoch: [4/100], Batch: [1/66], train accuracy: 52.244898%, loss: 5.985426\n",
            "Epoch: [4/100], train loss: 0.001411\n",
            "Epoch: [4/100], validation accuracy: 54.201681%, loss: 0.086398\n",
            "Epoch: [5/100], Batch: [1/66], train accuracy: 56.158463%, loss: 5.890804\n",
            "Epoch: [5/100], train loss: 0.001413\n",
            "Epoch: [5/100], validation accuracy: 54.621849%, loss: 0.086056\n",
            "Epoch: [6/100], Batch: [1/66], train accuracy: 57.022809%, loss: 5.862510\n",
            "Epoch: [6/100], train loss: 0.001410\n",
            "Epoch: [6/100], validation accuracy: 54.957983%, loss: 0.086300\n",
            "Epoch: [7/100], Batch: [1/66], train accuracy: 57.551020%, loss: 6.110507\n",
            "Epoch: [7/100], train loss: 0.001463\n",
            "Epoch: [7/100], validation accuracy: 54.285714%, loss: 0.086004\n",
            "Epoch: [8/100], Batch: [1/66], train accuracy: 55.798319%, loss: 6.045769\n",
            "Epoch: [8/100], train loss: 0.001409\n",
            "Epoch: [8/100], validation accuracy: 52.100840%, loss: 0.087292\n",
            "Epoch: [9/100], Batch: [1/66], train accuracy: 53.061224%, loss: 6.084011\n",
            "Epoch: [9/100], train loss: 0.001456\n",
            "Epoch: [9/100], validation accuracy: 53.109244%, loss: 0.087304\n",
            "Epoch: [10/100], Batch: [1/66], train accuracy: 55.582233%, loss: 5.830370\n",
            "Epoch: [10/100], train loss: 0.001519\n",
            "Epoch: [10/100], validation accuracy: 50.420168%, loss: 0.090237\n",
            "Epoch: [11/100], Batch: [1/66], train accuracy: 52.893157%, loss: 6.315320\n",
            "Epoch: [11/100], train loss: 0.001477\n",
            "Epoch: [11/100], validation accuracy: 52.773109%, loss: 0.087437\n",
            "Epoch: [12/100], Batch: [1/66], train accuracy: 54.645858%, loss: 6.049854\n",
            "Epoch: [12/100], train loss: 0.001461\n",
            "Epoch: [12/100], validation accuracy: 56.134454%, loss: 0.088005\n",
            "Epoch: [13/100], Batch: [1/66], train accuracy: 57.190876%, loss: 6.144934\n",
            "Epoch: [13/100], train loss: 0.001411\n",
            "Epoch: [13/100], validation accuracy: 52.521008%, loss: 0.085776\n",
            "Epoch: [14/100], Batch: [1/66], train accuracy: 55.198079%, loss: 6.099489\n",
            "Epoch: [14/100], train loss: 0.001426\n",
            "Epoch: [14/100], validation accuracy: 57.226891%, loss: 0.088094\n",
            "Epoch: [15/100], Batch: [1/66], train accuracy: 57.070828%, loss: 6.129921\n",
            "Epoch: [15/100], train loss: 0.001405\n",
            "Epoch: [15/100], validation accuracy: 53.949580%, loss: 0.086385\n",
            "Epoch: [16/100], Batch: [1/66], train accuracy: 55.270108%, loss: 6.105239\n",
            "Epoch: [16/100], train loss: 0.001457\n",
            "Epoch: [16/100], validation accuracy: 50.840336%, loss: 0.089857\n",
            "Epoch: [17/100], Batch: [1/66], train accuracy: 54.309724%, loss: 5.876279\n",
            "Epoch: [17/100], train loss: 0.001464\n",
            "Epoch: [17/100], validation accuracy: 53.193277%, loss: 0.088071\n",
            "Epoch: [18/100], Batch: [1/66], train accuracy: 54.477791%, loss: 5.868289\n",
            "Epoch: [18/100], train loss: 0.001402\n",
            "Epoch: [18/100], validation accuracy: 49.747899%, loss: 0.084364\n",
            "Epoch: [19/100], Batch: [1/66], train accuracy: 53.565426%, loss: 5.850517\n",
            "Epoch: [19/100], train loss: 0.001455\n",
            "Epoch: [19/100], validation accuracy: 50.924370%, loss: 0.085877\n",
            "Epoch: [20/100], Batch: [1/66], train accuracy: 54.261705%, loss: 5.832516\n"
          ]
        }
      ]
    }
  ]
}